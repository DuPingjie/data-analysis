{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TD3 : Supervised learning (2/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the script `datasets.py` like you did in the last notebook to load the functions used to generate artificial datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Models for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the make_forge() function to generate a set of 500 points X and\n",
    "# their labels y for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this snippet prints the points on a 2d space\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib\n",
    "plt.scatter(X[:,0], X[:,1], c=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the dataset does not seem to be linearly separable. We are going to use a logistic regression model to create a classifier. Add the missing pieces of code to create a model and train it. Print its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Add your code HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now print the decision boundary of this model like what we did in the last notebook. Save the image (with code or the button in the GUI) for future model comparison. Find also the number of misclassified examples by your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear models for classification can also have a regularization. Read the source code of `LogisticRegression` to find the parameter used to control the regularization. Create other models (at least 4) with different values for this parameter. Print the accuracy of each of your model, the number of misclassified examples and the decision boundary. Save the image for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some LogisticRegression() models with regularization\n",
    "# Visualize their respective decision boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the images of decision boundaries you have saved. Can you see the influence of the regularization parameter ? Can the parameter help to prevent overfitting or underfitting ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the weight $w$ and $b$ learned by your models. Does the regularization parameter has an influence on the values of theses coefficients ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the coefficients HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first see a toy example to visualize what are decision trees and how they create decision boundary in the dataset. Run the follwing pieces of code, but first, run these two commands in a terminal in your machine (to install the software that can generate decision trees)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sudo pip3 install graphviz --proxy http://cache.univ-st-etienne.fr:3128`\n",
    "\n",
    "`sudo pip3 install pillow --proxy http://cache.univ-st-etienne.fr:3128`\n",
    "\n",
    "`sudo apt-get install graphviz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now run this cell\n",
    "%run plot_interactive_tree.py\n",
    "plot_tree_progressive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use a decision tree on a real dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the breast cancer dataset. Separate it into\n",
    "# a training and a test file\n",
    "\n",
    "# your code HERE\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(random_state=0)\n",
    "tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the accuracy on training and test set. What can you \n",
    "# say about these scores ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the documentation of DecisionTreeClassifier() and\n",
    "# train a model named tree that only has a depth of 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can save the DecisionTreeClassifier model as a tree image.\n",
    "from sklearn.tree import export_graphviz\n",
    "export_graphviz(tree, out_file=\"breast_tree.dot\", \n",
    "                class_names=[\"malignant\", \"benign\"],\n",
    "                feature_names=cancer.feature_names,\n",
    "                impurity=False,\n",
    "                filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with ls, you can see that the file breast_tree.dot has been created\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can visualize this .dot image with graphviz\n",
    "import graphviz\n",
    "with open(\"breast_tree.dot\") as f:\n",
    "    breast_tree = f.read()\n",
    "graphviz.Source(breast_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can visualize the importance of each feature\n",
    "# learned by our model\n",
    "#plt.figure(figsize=(10, 12))\n",
    "plt.plot(tree.feature_importances_, 'o')\n",
    "plt.xticks(range(cancer.data.shape[1]), cancer.feature_names, rotation=90)\n",
    "plt.ylim(0,1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
